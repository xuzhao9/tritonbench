{
    "aten._log_softmax.default": {
        "count": 10,
        "inputs": "((T([6, 474], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 10,
        "inputs": "((T([6, 474], f32), T([6, 474], f32), 1, f32), {})"
    },
    "aten._softmax.default": {
        "count": 60,
        "inputs": "((T([6, 12, 476, 476], f32), -1, False), {})"
    },
    "aten._softmax_backward_data.default": {
        "count": 60,
        "inputs": "((T([6, 12, 476, 476], f32), T([6, 12, 476, 476], f32), -1, f32), {})"
    },
    "aten._to_copy.default": {
        "count": 5,
        "inputs": "((T([6, 474], i64, stride=(0, 1)),), {'dtype': i64, 'device': 'cuda'})"
    },
    "aten._unsafe_view.default": {
        "count": 60,
        "inputs": "((T([6, 476, 768], f32), [2856, 768]), {})"
    },
    "aten.add.Tensor": {
        "count": 60,
        "inputs": "((T([6, 476, 3072], f32), T([6, 476, 3072], f32)), {})"
    },
    "aten.add_.Tensor": {
        "count": 4,
        "inputs": "((T([21128, 768], f32), T([21128, 768], f32)), {})"
    },
    "aten.addmm.default": {
        "count": 5,
        "inputs": "((T([2], f32), T([2844, 768], f32), T([768, 2], f32, stride=(1, 768))), {})"
    },
    "aten.bernoulli.default": {
        "count": 5,
        "inputs": "((T([6, 474], f32),), {})"
    },
    "aten.bitwise_and.Tensor": {
        "count": 10,
        "inputs": "((T([6, 474], b8), T([6, 474], b8)), {})"
    },
    "aten.bitwise_xor.Tensor": {
        "count": 5,
        "inputs": "((T([6, 1], i64, stride=(476, 1)), T([6, 476], i64)), {})"
    },
    "aten.bmm.default": {
        "count": 60,
        "inputs": "((T([72, 476, 476], f32), T([72, 476, 64], f32, stride=(30464, 1, 476))), {})"
    },
    "aten.cat.default": {
        "count": 5,
        "inputs": "(([T([6, 474, 768], f32)], -1), {})"
    },
    "aten.copy_.default": {
        "count": 5,
        "inputs": "((T([1, 6, 474, 768], f32), T([1, 6, 474, 768], f32)), {})"
    },
    "aten.cumsum.default": {
        "count": 5,
        "inputs": "((T([6, 474], i64), -1), {})"
    },
    "aten.div.Scalar": {
        "count": 5,
        "inputs": "((T([], f32), 1), {})"
    },
    "aten.div.Tensor": {
        "count": 10,
        "inputs": "((T([], f32), 2), {})"
    },
    "aten.embedding.default": {
        "count": 5,
        "inputs": "((T([2, 768], f32), T([6, 476], i64)), {})"
    },
    "aten.embedding_dense_backward.default": {
        "count": 5,
        "inputs": "((T([6, 476, 768], f32), T([6, 476], i64), 21128, 0, False), {})"
    },
    "aten.eq.Scalar": {
        "count": 5,
        "inputs": "((T([6, 474, 1], b8), False), {})"
    },
    "aten.erf.default": {
        "count": 60,
        "inputs": "((T([6, 476, 3072], f32),), {})"
    },
    "aten.exp.default": {
        "count": 60,
        "inputs": "((T([6, 476, 3072], f32),), {})"
    },
    "aten.fill_.Scalar": {
        "count": 5,
        "inputs": "((T([6], i64, stride=(476,)), 1292), {})"
    },
    "aten.flip.default": {
        "count": 10,
        "inputs": "((T([6, 476], i64), [-1]), {})"
    },
    "aten.fmod.Scalar": {
        "count": 5,
        "inputs": "((T([6, 476], i64), 2), {})"
    },
    "aten.ge.Scalar": {
        "count": 5,
        "inputs": "((T([6, 474], i64, stride=(475, 1)), 474), {})"
    },
    "aten.index.Tensor": {
        "count": 5,
        "inputs": "((T([6, 474, 768], f32, stride=(365568, 768, 1)), [T([6, 474], i64, stride=(1, 0)), T([6, 474], i64, stride=(475, 1))]), {})"
    },
    "aten.index_put.default": {
        "count": 5,
        "inputs": "((T([6, 474, 768], f32), [T([6, 474], i64, stride=(1, 0)), T([6, 474], i64, stride=(475, 1))], T([6, 474, 768], f32), True), {})"
    },
    "aten.index_put_.default": {
        "count": 5,
        "inputs": "((T([6, 476], i64), [T([6], i64), T([6], i64)], T([], i64)), {})"
    },
    "aten.lt.Tensor": {
        "count": 5,
        "inputs": "((T([6, 474], i64), T([6, 1], i64)), {})"
    },
    "aten.masked_fill.Scalar": {
        "count": 10,
        "inputs": "((T([6, 474], f32), T([6, 474], b8), 0), {})"
    },
    "aten.masked_fill_.Scalar": {
        "count": 5,
        "inputs": "((T([6, 474], i64, stride=(475, 1)), T([6, 474], b8), 0), {})"
    },
    "aten.max.default": {
        "count": 10,
        "inputs": "((T([6], i64),), {})"
    },
    "aten.mean.default": {
        "count": 5,
        "inputs": "((T([], f32),), {})"
    },
    "aten.mm.default": {
        "count": 240,
        "inputs": "((T([768, 2856], f32, stride=(1, 768)), T([2856, 768], f32)), {})"
    },
    "aten.mul.Scalar": {
        "count": 60,
        "inputs": "((T([6, 476, 3072], f32), 1.1283791670955126), {})"
    },
    "aten.mul.Tensor": {
        "count": 240,
        "inputs": "((T([6, 476, 3072], f32), T([6, 476, 3072], f32)), {})"
    },
    "aten.native_dropout.default": {
        "count": 5,
        "inputs": "((T([6, 474, 768], f32), 0.5, True), {})"
    },
    "aten.native_dropout_backward.default": {
        "count": 60,
        "inputs": "((T([6, 12, 476, 476], f32), T([6, 12, 476, 476], b8), 1.1111111111111112), {})"
    },
    "aten.native_layer_norm.default": {
        "count": 125,
        "inputs": "((T([6, 476, 768], f32), [768], T([768], f32), T([768], f32), 1e-12), {})"
    },
    "aten.native_layer_norm_backward.default": {
        "count": 125,
        "inputs": "((T([6, 476, 768], f32), T([6, 476, 768], f32), [768], T([6, 476, 1], f32), T([6, 476, 1], f32), T([768], f32), T([768], f32), [True, True, True]), {})"
    },
    "aten.ne.Scalar": {
        "count": 5,
        "inputs": "((T([6, 474], i64), 2), {})"
    },
    "aten.neg.default": {
        "count": 60,
        "inputs": "((T([6, 476, 3072], f32),), {})"
    },
    "aten.new_empty_strided.default": {
        "count": 5,
        "inputs": "((T([1, 6, 474, 768], f32), [1, 6, 474, 768], [2184192, 364032, 768, 1]), {})"
    },
    "aten.new_full.default": {
        "count": 5,
        "inputs": "((T([6, 474], i64), [6, 476], 2566), {'pin_memory': False})"
    },
    "aten.new_zeros.default": {
        "count": 5,
        "inputs": "((T([6, 474, 768], f32), [6, 474, 768]), {'dtype': f32, 'layout': torch.strided, 'device': 'cuda'})"
    },
    "aten.nll_loss_backward.default": {
        "count": 10,
        "inputs": "((T([], f32), T([6, 474], f32), T([6], i64), None, 2, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 10,
        "inputs": "((T([6, 474], f32), T([6], i64), None, 2, -100), {})"
    },
    "aten.pow.Tensor_Scalar": {
        "count": 60,
        "inputs": "((T([6, 476, 3072], f32), 2), {})"
    },
    "aten.rsub.Scalar": {
        "count": 5,
        "inputs": "((T([6, 1, 1, 476], f32), 1.0), {})"
    },
    "aten.select_backward.default": {
        "count": 5,
        "inputs": "((T([6, 474], f32), [6, 474, 2], 2, 0), {})"
    },
    "aten.slice_backward.default": {
        "count": 5,
        "inputs": "((T([6, 474, 768], f32), [6, 476, 768], 1, 1, -1, 1), {})"
    },
    "aten.stack.default": {
        "count": 5,
        "inputs": "(([T([6, 474, 768], f32)],), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 60,
        "inputs": "((T([2856, 3072], f32), [0], True), {})"
    },
    "aten.tanh.default": {
        "count": 5,
        "inputs": "((T([6, 768], f32),), {})"
    },
    "aten.unbind.int": {
        "count": 5,
        "inputs": "((T([1, 6, 474, 768], f32),), {})"
    }
}