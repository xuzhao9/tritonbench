{
    "aten._foreach_add.List": {
        "count": 1,
        "inputs": "(([T([512, 256, 1, 1], f32), T([128, 256, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([128, 512, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([128, 512, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([128, 512, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([1024, 512, 1, 1], f32), T([256, 512, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([2048, 1024, 1, 1], f32), T([512, 1024, 1, 1], f32), T([512, 512, 3, 3], f32), T([2048, 512, 1, 1], f32), T([512, 2048, 1, 1], f32), T([512, 512, 3, 3], f32), T([2048, 512, 1, 1], f32), T([512, 2048, 1, 1], f32), T([512, 512, 3, 3], f32), T([2048, 512, 1, 1], f32), T([2048, 2048, 3, 3], f32), T([2048], f32), T([15, 2048, 1, 1], f32), T([15], f32), T([60, 2048, 1, 1], f32), T([60], f32), T([1024, 100352], f32), T([1024], f32), T([1024, 1024], f32), T([1024], f32), T([81, 1024], f32), T([81], f32), T([320, 1024], f32), T([320], f32)], [T([512, 256, 1, 1], f32), T([128, 256, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([128, 512, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([128, 512, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([128, 512, 1, 1], f32), T([128, 128, 3, 3], f32), T([512, 128, 1, 1], f32), T([1024, 512, 1, 1], f32), T([256, 512, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([256, 1024, 1, 1], f32), T([256, 256, 3, 3], f32), T([1024, 256, 1, 1], f32), T([2048, 1024, 1, 1], f32), T([512, 1024, 1, 1], f32), T([512, 512, 3, 3], f32), T([2048, 512, 1, 1], f32), T([512, 2048, 1, 1], f32), T([512, 512, 3, 3], f32), T([2048, 512, 1, 1], f32), T([512, 2048, 1, 1], f32), T([512, 512, 3, 3], f32), T([2048, 512, 1, 1], f32), T([2048, 2048, 3, 3], f32), T([2048], f32), T([15, 2048, 1, 1], f32), T([15], f32), T([60, 2048, 1, 1], f32), T([60], f32), T([1024, 100352], f32), T([1024], f32), T([1024, 1024], f32), T([1024], f32), T([81, 1024], f32), T([81], f32), T([320, 1024], f32), T([320], f32)]), {'alpha': 0.0001})"
    },
    "aten._log_softmax.default": {
        "count": 1,
        "inputs": "((T([512, 81], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 1,
        "inputs": "((T([512, 81], f32), T([512, 81], f32), 1, f32), {})"
    },
    "aten._to_copy.default": {
        "count": 1,
        "inputs": "((T([1], i64),), {'dtype': i64, 'layout': torch.strided, 'device': 'cuda'})"
    },
    "aten._unsafe_view.default": {
        "count": 1,
        "inputs": "((T([1, 47, 84, 15, 4], f32), [1, 59220, 4]), {})"
    },
    "aten.abs.default": {
        "count": 1,
        "inputs": "((T([1, 128, 4], f32),), {})"
    },
    "aten.add.Tensor": {
        "count": 4,
        "inputs": "((T([1, 512, 94, 167], f32), T([1, 512, 94, 167], f32)), {})"
    },
    "aten.add_.Tensor": {
        "count": 3,
        "inputs": "((T([1, 2048, 47, 84], f32), T([1, 2048, 47, 84], f32)), {})"
    },
    "aten.addmm.default": {
        "count": 1,
        "inputs": "((T([320], f32), T([512, 1024], f32), T([1024, 320], f32, stride=(1, 1024))), {})"
    },
    "aten.all.default": {
        "count": 1,
        "inputs": "((T([128], b8),), {})"
    },
    "aten.all.dim": {
        "count": 1,
        "inputs": "((T([12000, 4], b8), 1), {})"
    },
    "aten.argmax.default": {
        "count": 1,
        "inputs": "((T([512, 81], f32), 1), {})"
    },
    "aten.binary_cross_entropy_with_logits.default": {
        "count": 1,
        "inputs": "((T([256], f32), T([256], f32), None, None, 2), {})"
    },
    "aten.bitwise_and.Tensor": {
        "count": 2,
        "inputs": "((T([512], b8), T([512], b8)), {})"
    },
    "aten.cat.default": {
        "count": 1,
        "inputs": "(([T([512, 1], f32), T([512, 4], f32)], 1), {})"
    },
    "aten.clamp.default": {
        "count": 2,
        "inputs": "((T([12000], f32, stride=(4,)), 0, 748), {})"
    },
    "aten.clamp_.default": {
        "count": 1,
        "inputs": "((T([21, 2021, 2], f32), 0), {})"
    },
    "aten.clone.default": {
        "count": 1,
        "inputs": "((T([320], f32),), {})"
    },
    "aten.constant_pad_nd.default": {
        "count": 1,
        "inputs": "((T([3, 748, 1333], f32), [0, 0, 0, 0], 0.0), {})"
    },
    "aten.convolution.default": {
        "count": 1,
        "inputs": "((T([1, 2048, 47, 84], f32), T([60, 2048, 1, 1], f32), T([60], f32), [1, 1], [0, 0], [1, 1], False, [0, 0], 1), {})"
    },
    "aten.convolution_backward.default": {
        "count": 1,
        "inputs": "((T([1, 128, 94, 167], f32), T([1, 256, 187, 334], f32), T([128, 256, 1, 1], f32), [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [False, True, False]), {})"
    },
    "aten.cudnn_batch_norm.default": {
        "count": 4,
        "inputs": "((T([1, 256, 187, 334], f32), T([256], f32), T([256], f32), T([256], f32), T([256], f32), False, 0.1, 1e-05), {})"
    },
    "aten.div.Tensor": {
        "count": 2,
        "inputs": "((T([], f32), 512), {})"
    },
    "aten.eq.Scalar": {
        "count": 1,
        "inputs": "((T([128], i64), 80), {})"
    },
    "aten.eq.Tensor": {
        "count": 1,
        "inputs": "((T([128], i64), T([128], i64)), {})"
    },
    "aten.exp.default": {
        "count": 2,
        "inputs": "((T([59220, 1], f32),), {})"
    },
    "aten.fill_.Scalar": {
        "count": 1,
        "inputs": "((T([59220], i8), -1), {})"
    },
    "aten.ge.Scalar": {
        "count": 2,
        "inputs": "((T([512], i64), 0), {})"
    },
    "aten.gt.Scalar": {
        "count": 1,
        "inputs": "((T([128], f32), 0), {})"
    },
    "aten.index.Tensor": {
        "count": 2,
        "inputs": "((T([512, 4], f32), [T([128], i64)]), {})"
    },
    "aten.index_put.default": {
        "count": 1,
        "inputs": "((T([1, 59220, 4], f32), [T([1, 59220], b8)], T([128, 4], f32), True), {})"
    },
    "aten.index_put_.default": {
        "count": 2,
        "inputs": "((T([2021], i64), [T([2021], b8)], T([], i64)), {})"
    },
    "aten.index_select.default": {
        "count": 1,
        "inputs": "((T([1], f32), 0, T([512], i64)), {})"
    },
    "aten.log.default": {
        "count": 2,
        "inputs": "((T([128], f32),), {})"
    },
    "aten.lt.Scalar": {
        "count": 2,
        "inputs": "((T([512], i64), 80), {})"
    },
    "aten.max.default": {
        "count": 1,
        "inputs": "((T([12000, 4], f32),), {})"
    },
    "aten.max.dim": {
        "count": 1,
        "inputs": "((T([21, 2021], f32), 0), {})"
    },
    "aten.max_pool2d_with_indices.default": {
        "count": 1,
        "inputs": "((T([1, 64, 374, 667], f32), [3, 3], [2, 2], [1, 1]), {})"
    },
    "aten.maximum.default": {
        "count": 1,
        "inputs": "((T([21, 1, 2], f32, stride=(4, 4, 1)), T([2021, 2], f32, stride=(4, 1))), {})"
    },
    "aten.minimum.default": {
        "count": 1,
        "inputs": "((T([21, 1, 2], f32, stride=(4, 4, 1)), T([2021, 2], f32, stride=(4, 1))), {})"
    },
    "aten.mm.default": {
        "count": 1,
        "inputs": "((T([1024, 512], f32, stride=(1, 1024)), T([512, 100352], f32)), {})"
    },
    "aten.mul.Tensor": {
        "count": 1,
        "inputs": "((T([128, 4], f32, stride=(0, 0)), T([128, 4], f32)), {})"
    },
    "aten.ne.Scalar": {
        "count": 1,
        "inputs": "((T([2021], i64), 80), {})"
    },
    "aten.new_full.default": {
        "count": 1,
        "inputs": "((T([2021], i64), [2021], 1), {'dtype': i8, 'pin_memory': False})"
    },
    "aten.new_zeros.default": {
        "count": 1,
        "inputs": "((T([128, 4], f32), [1, 59220, 4]), {'dtype': f32, 'layout': torch.strided, 'device': 'cuda'})"
    },
    "aten.nll_loss_backward.default": {
        "count": 1,
        "inputs": "((T([], f32), T([512, 81], f32), T([512], i64), None, 1, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 1,
        "inputs": "((T([512, 81], f32), T([512], i64), None, 1, -100), {})"
    },
    "aten.nonzero.default": {
        "count": 2,
        "inputs": "((T([128], b8),), {})"
    },
    "aten.prod.dim_int": {
        "count": 1,
        "inputs": "((T([21, 2021, 2], f32), 2), {})"
    },
    "aten.relu.default": {
        "count": 2,
        "inputs": "((T([512, 1024], f32),), {})"
    },
    "aten.relu_.default": {
        "count": 3,
        "inputs": "((T([1, 2048, 47, 84], f32),), {})"
    },
    "aten.repeat_interleave.Tensor": {
        "count": 1,
        "inputs": "((T([1], i64),), {})"
    },
    "aten.rsqrt.default": {
        "count": 4,
        "inputs": "((T([2048], f32),), {})"
    },
    "aten.scatter_.value": {
        "count": 1,
        "inputs": "((T([59220], i8), 0, T([128], i64), 0), {})"
    },
    "aten.sgn.default": {
        "count": 1,
        "inputs": "((T([128, 4], f32),), {})"
    },
    "aten.sigmoid.default": {
        "count": 1,
        "inputs": "((T([256], f32),), {})"
    },
    "aten.stack.default": {
        "count": 1,
        "inputs": "(([T([128, 4], f32)],), {})"
    },
    "aten.sub.Tensor": {
        "count": 1,
        "inputs": "((T([1, 128, 4], f32), T([1, 128, 4], f32)), {})"
    },
    "aten.sum.default": {
        "count": 1,
        "inputs": "((T([1, 128, 4], f32),), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 2,
        "inputs": "((T([512, 1024], f32), [0], True), {})"
    },
    "aten.threshold_backward.default": {
        "count": 8,
        "inputs": "((T([1, 128, 94, 167], f32), T([1, 128, 94, 167], f32), 0), {})"
    },
    "aten.topk.default": {
        "count": 1,
        "inputs": "((T([1, 59220], f32), 12000, 1), {})"
    },
    "aten.unbind.int": {
        "count": 1,
        "inputs": "((T([128, 1], i64), 1), {})"
    },
    "aten.unsqueeze_.default": {
        "count": 1,
        "inputs": "((T([3, 748, 1333], f32), 0), {})"
    },
    "aten.where.self": {
        "count": 1,
        "inputs": "((T([21, 2021], b8), T([21, 2021], f32), T([1], f32)), {})"
    },
    "torchvision._roi_align_backward.default": {
        "count": 1,
        "inputs": "((T([512, 2048, 7, 7], f32), T([512, 5], f32), 0.0625, 7, 7, 1, 2048, 47, 84, 0, True), {})"
    },
    "torchvision.nms.default": {
        "count": 1,
        "inputs": "((T([12000, 4], f32), T([12000], f32), 0.7), {})"
    },
    "torchvision.roi_align.default": {
        "count": 1,
        "inputs": "((T([1, 2048, 47, 84], f32), T([512, 5], f32), 0.0625, 7, 7, 0, True), {})"
    }
}