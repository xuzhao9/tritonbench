{
    "aten._cudnn_rnn.default": {
        "count": 2,
        "inputs": "((T([64, 50, 256], f32), [T([3072, 256], f32), T([3072, 768], f32), T([3072], f32), T([3072], f32)], 4, T([3151872], f32), T([1, 64, 768], f32), T([1, 64, 768], f32), 2, 768, 0, 1, True, 0.0, True, False, [], None), {})"
    },
    "aten._cudnn_rnn_backward.default": {
        "count": 1,
        "inputs": "((T([64, 50, 40], f32), [T([3072, 40], f32), T([3072, 768], f32), T([3072], f32), T([3072], f32)], 4, T([2488320], f32), T([1, 64, 768], f32), T([1, 64, 768], f32), T([64, 50, 768], f32, stride=(768, 49152, 1)), T([64, 50, 768], f32), None, None, 2, 768, 0, 1, True, 0.0, True, False, [], None, T([49152256], u8), [False, False, False, True]), {})"
    },
    "aten._cudnn_rnn_flatten_weight.default": {
        "count": 2,
        "inputs": "(([T([3072, 256], f32), T([3072, 768], f32), T([3072], f32), T([3072], f32)], 4, 256, 2, 768, 0, 1, True, False), {})"
    },
    "aten._log_softmax.default": {
        "count": 1,
        "inputs": "((T([64, 64], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 1,
        "inputs": "((T([64, 64], f32), T([64, 64], f32), 1, f32), {})"
    },
    "aten._to_copy.default": {
        "count": 1,
        "inputs": "((T([64], i64),), {'dtype': i64, 'layout': torch.strided, 'device': 'cuda'})"
    },
    "aten._unsafe_view.default": {
        "count": 2,
        "inputs": "((T([64, 50, 256], f32), [3200, 256]), {})"
    },
    "aten.add.Tensor": {
        "count": 1,
        "inputs": "((T([64, 256], f32), T([64, 256], f32)), {})"
    },
    "aten.add_.Tensor": {
        "count": 2,
        "inputs": "((T([3072, 256], f32), T([3072, 256], f32)), {'alpha': -0.0010000000000000002})"
    },
    "aten.addcmul_.default": {
        "count": 2,
        "inputs": "((T([3072, 256], f32), T([3072, 256], f32), T([3072, 256], f32)), {'value': 0.0010000000000000009})"
    },
    "aten.clamp.default": {
        "count": 1,
        "inputs": "((T([], f32), 1e-06), {})"
    },
    "aten.clamp_min.default": {
        "count": 1,
        "inputs": "((T([64, 1], f32), 1e-12), {})"
    },
    "aten.clamp_min_.default": {
        "count": 2,
        "inputs": "((T([64, 1, 64], f32), 1e-08), {})"
    },
    "aten.clone.default": {
        "count": 2,
        "inputs": "((T([64, 1, 64], f32),), {})"
    },
    "aten.copy_.default": {
        "count": 2,
        "inputs": "((T([3072, 256], f32), T([3072, 256], f32)), {})"
    },
    "aten.div.Scalar": {
        "count": 1,
        "inputs": "((T([64, 0, 256], f32), 0), {})"
    },
    "aten.div.Tensor": {
        "count": 1,
        "inputs": "((T([64, 256], f32, stride=(12800, 1)), T([64, 1], f32)), {})"
    },
    "aten.eq.Scalar": {
        "count": 1,
        "inputs": "((T([64, 1], f32), 0), {})"
    },
    "aten.ge.Scalar": {
        "count": 1,
        "inputs": "((T([64, 1], f32), 1e-12), {})"
    },
    "aten.linalg_vector_norm.default": {
        "count": 1,
        "inputs": "((T([64, 256, 64], f32, stride=(0, 1, 256)), 2, [1], True), {})"
    },
    "aten.masked_fill_.Scalar": {
        "count": 1,
        "inputs": "((T([64, 256], f32), T([64, 1], b8), 0), {})"
    },
    "aten.mean.dim": {
        "count": 1,
        "inputs": "((T([64, 0, 256], f32), [1]), {})"
    },
    "aten.mm.default": {
        "count": 3,
        "inputs": "((T([3200, 256], f32), T([256, 768], f32)), {})"
    },
    "aten.mul.Tensor": {
        "count": 1,
        "inputs": "((T([64, 1], f32), T([64, 256], f32)), {})"
    },
    "aten.mul_.Tensor": {
        "count": 2,
        "inputs": "((T([3072, 256], f32), 0.9), {})"
    },
    "aten.neg.default": {
        "count": 1,
        "inputs": "((T([64, 256], f32),), {})"
    },
    "aten.nll_loss_backward.default": {
        "count": 1,
        "inputs": "((T([], f32), T([64, 64], f32), T([64], i64), None, 1, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 1,
        "inputs": "((T([64, 64], f32), T([64], i64), None, 1, -100), {})"
    },
    "aten.select_backward.default": {
        "count": 1,
        "inputs": "((T([64, 256], f32), [64, 50, 256], 1, -1), {})"
    },
    "aten.slice_backward.default": {
        "count": 1,
        "inputs": "((T([64, 0, 256], f32), [64, 1, 256], 1, 1, 9223372036854775807, 1), {})"
    },
    "aten.sum.default": {
        "count": 2,
        "inputs": "((T([64, 64], f32),), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 1,
        "inputs": "((T([64, 256], f32), [1], True), {})"
    },
    "aten.where.self": {
        "count": 1,
        "inputs": "((T([64, 1], b8), T([64, 1], f32), T([], f32)), {})"
    }
}