{
    "aten._log_softmax.default": [
        {
            "count": 1,
            "inputs": "((T([2048, 128112], f32), 1, False), {})"
        }
    ],
    "aten._log_softmax_backward_data.default": [
        {
            "count": 1,
            "inputs": "((T([2048, 128112], f32), T([2048, 128112], f32), 1, f32), {})"
        }
    ],
    "aten._scaled_dot_product_efficient_attention.default": [
        {
            "count": 24,
            "inputs": "((T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), None, True, 0.1), {})"
        },
        {
            "count": 12,
            "inputs": "((T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), None, True, 0.1, True), {})"
        }
    ],
    "aten._scaled_dot_product_efficient_attention_backward.default": [
        {
            "count": 24,
            "inputs": "((T([16, 16, 128, 64], f32, stride=(131072, 64, 1024, 1)), T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), None, T([16, 16, 128, 64], f32, stride=(131072, 64, 1024, 1)), T([16, 16, 128], f32), T([], i64), T([], i64), 0.1, [True, True, True, False]), {})"
        },
        {
            "count": 12,
            "inputs": "((T([16, 16, 128, 64], f32, stride=(131072, 64, 1024, 1)), T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), T([16, 16, 128, 64], f32), None, T([16, 16, 128, 64], f32, stride=(131072, 64, 1024, 1)), T([16, 16, 128], f32), T([], i64), T([], i64), 0.1, [True, True, True, False], True), {})"
        }
    ],
    "aten._to_copy.default": [
        {
            "count": 2,
            "inputs": "((T([16, 128], b8),), {'dtype': i32})"
        },
        {
            "count": 2,
            "inputs": "((T([16, 128], i64),), {'dtype': i32, 'layout': torch.strided, 'device': 'cuda'})"
        },
        {
            "count": 2,
            "inputs": "((T([16, 128], i32),), {'dtype': i64})"
        }
    ],
    "aten._unsafe_view.default": [
        {
            "count": 1,
            "inputs": "((T([2048, 128112], f32), [16, 128, 128112]), {})"
        }
    ],
    "aten.add.Tensor": [
        {
            "count": 2,
            "inputs": "((T([16, 128], i32), 0), {})"
        },
        {
            "count": 2,
            "inputs": "((T([16, 128], i64), 1), {})"
        },
        {
            "count": 193,
            "inputs": "((T([16, 128, 1024], f32), T([16, 128, 1024], f32)), {})"
        },
        {
            "count": 2,
            "inputs": "((T([128112, 1024], f32), T([128112, 1024], f32)), {})"
        }
    ],
    "aten.addmm.default": [
        {
            "count": 144,
            "inputs": "((T([1024], f32), T([2048, 1024], f32), T([1024, 1024], f32, stride=(1, 1024))), {})"
        },
        {
            "count": 24,
            "inputs": "((T([4096], f32), T([2048, 1024], f32), T([1024, 4096], f32, stride=(1, 1024))), {})"
        },
        {
            "count": 24,
            "inputs": "((T([1024], f32), T([2048, 4096], f32), T([4096, 1024], f32, stride=(1, 4096))), {})"
        }
    ],
    "aten.any.default": [
        {
            "count": 1,
            "inputs": "((T([16, 2], b8),), {})"
        }
    ],
    "aten.cumsum.default": [
        {
            "count": 2,
            "inputs": "((T([16, 128], i32), 1), {})"
        }
    ],
    "aten.embedding.default": [
        {
            "count": 2,
            "inputs": "((T([128112, 1024], f32), T([16, 128], i64), 1), {})"
        }
    ],
    "aten.embedding_dense_backward.default": [
        {
            "count": 2,
            "inputs": "((T([16, 128, 1024], f32), T([16, 128], i64), 128112, 1, False), {})"
        }
    ],
    "aten.eq.Scalar": [
        {
            "count": 1,
            "inputs": "((T([16, 2], i64), 1), {})"
        }
    ],
    "aten.index.Tensor": [
        {
            "count": 1,
            "inputs": "((T([16, 128], i64), [None, T([2], i64)]), {})"
        }
    ],
    "aten.index_select.default": [
        {
            "count": 2,
            "inputs": "((T([1026, 1024], f32), 0, T([2048], i64)), {})"
        }
    ],
    "aten.lt.Scalar": [
        {
            "count": 24,
            "inputs": "((T([], f32), 0.05), {})"
        }
    ],
    "aten.mm.default": [
        {
            "count": 1,
            "inputs": "((T([2048, 1024], f32), T([1024, 128112], f32, stride=(1, 1024))), {})"
        },
        {
            "count": 1,
            "inputs": "((T([128112, 2048], f32, stride=(1, 128112)), T([2048, 1024], f32)), {})"
        },
        {
            "count": 1,
            "inputs": "((T([2048, 128112], f32), T([128112, 1024], f32)), {})"
        },
        {
            "count": 24,
            "inputs": "((T([2048, 1024], f32), T([1024, 4096], f32)), {})"
        },
        {
            "count": 24,
            "inputs": "((T([1024, 2048], f32, stride=(1, 1024)), T([2048, 4096], f32)), {})"
        },
        {
            "count": 24,
            "inputs": "((T([2048, 4096], f32), T([4096, 1024], f32)), {})"
        },
        {
            "count": 24,
            "inputs": "((T([4096, 2048], f32, stride=(1, 4096)), T([2048, 1024], f32)), {})"
        },
        {
            "count": 144,
            "inputs": "((T([2048, 1024], f32), T([1024, 1024], f32)), {})"
        },
        {
            "count": 144,
            "inputs": "((T([1024, 2048], f32, stride=(1, 1024)), T([2048, 1024], f32)), {})"
        }
    ],
    "aten.mul.Tensor": [
        {
            "count": 4,
            "inputs": "((T([16, 128, 1024], f32), 32.0), {})"
        },
        {
            "count": 2,
            "inputs": "((T([16, 128], i32), T([16, 128], i32)), {})"
        }
    ],
    "aten.native_dropout.default": [
        {
            "count": 62,
            "inputs": "((T([16, 128, 1024], f32), 0.1, True), {})"
        }
    ],
    "aten.native_dropout_backward.default": [
        {
            "count": 62,
            "inputs": "((T([16, 128, 1024], f32), T([16, 128, 1024], b8), 1.1111111111111112), {})"
        }
    ],
    "aten.native_layer_norm.default": [
        {
            "count": 62,
            "inputs": "((T([16, 128, 1024], f32), [1024], T([1024], f32), T([1024], f32), 1e-05), {})"
        }
    ],
    "aten.native_layer_norm_backward.default": [
        {
            "count": 62,
            "inputs": "((T([16, 128, 1024], f32), T([16, 128, 1024], f32), [1024], T([16, 128, 1], f32), T([16, 128, 1], f32), T([1024], f32), T([1024], f32), [True, True, True]), {})"
        }
    ],
    "aten.ne.Scalar": [
        {
            "count": 2,
            "inputs": "((T([16, 128], i64), 1), {})"
        }
    ],
    "aten.nll_loss_backward.default": [
        {
            "count": 1,
            "inputs": "((T([], f32), T([2048, 128112], f32), T([2048], i64), None, 1, -100, T([], f32)), {})"
        }
    ],
    "aten.nll_loss_forward.default": [
        {
            "count": 1,
            "inputs": "((T([2048, 128112], f32), T([2048], i64), None, 1, -100), {})"
        }
    ],
    "aten.relu.default": [
        {
            "count": 24,
            "inputs": "((T([16, 128, 4096], f32),), {})"
        }
    ],
    "aten.sum.dim_IntList": [
        {
            "count": 168,
            "inputs": "((T([2048, 1024], f32), [0], True), {})"
        },
        {
            "count": 24,
            "inputs": "((T([2048, 4096], f32), [0], True), {})"
        }
    ],
    "aten.threshold_backward.default": [
        {
            "count": 24,
            "inputs": "((T([16, 128, 4096], f32), T([16, 128, 4096], f32), 0), {})"
        }
    ]
}