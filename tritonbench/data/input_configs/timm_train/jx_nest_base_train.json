{
    "aten._foreach_add.List": {
        "count": 1,
        "inputs": "(([T([128, 3, 4, 4], f32), T([1, 16, 196, 128], f32), T([384, 128], f32), T([128, 128], f32), T([512, 128], f32), T([128, 512], f32), T([384, 128], f32), T([128, 128], f32), T([512, 128], f32), T([128, 512], f32), T([1, 4, 196, 256], f32), T([256, 128, 3, 3], f32), T([768, 256], f32), T([256, 256], f32), T([1024, 256], f32), T([256, 1024], f32), T([768, 256], f32), T([256, 256], f32), T([1024, 256], f32), T([256, 1024], f32), T([1, 1, 196, 512], f32), T([512, 256, 3, 3], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1000, 512], f32)], [T([128, 3, 4, 4], f32), T([1, 16, 196, 128], f32), T([384, 128], f32), T([128, 128], f32), T([512, 128], f32), T([128, 512], f32), T([384, 128], f32), T([128, 128], f32), T([512, 128], f32), T([128, 512], f32), T([1, 4, 196, 256], f32), T([256, 128, 3, 3], f32), T([768, 256], f32), T([256, 256], f32), T([1024, 256], f32), T([256, 1024], f32), T([768, 256], f32), T([256, 256], f32), T([1024, 256], f32), T([256, 1024], f32), T([1, 1, 196, 512], f32), T([512, 256, 3, 3], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1536, 512], f32), T([512, 512], f32), T([2048, 512], f32), T([512, 2048], f32), T([1000, 512], f32)]), {'alpha': 0.0001})"
    },
    "aten._log_softmax.default": {
        "count": 1,
        "inputs": "((T([32, 1000], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 1,
        "inputs": "((T([32, 1000], f32), T([32, 1000], f32), 1, f32), {})"
    },
    "aten._safe_softmax.default": {
        "count": 20,
        "inputs": "((T([32, 16, 1, 196, 196], f32), -1), {})"
    },
    "aten._softmax_backward_data.default": {
        "count": 2,
        "inputs": "((T([32, 4, 16, 196, 196], f32), T([32, 4, 16, 196, 196], f32), -1, f32), {})"
    },
    "aten._unsafe_view.default": {
        "count": 2,
        "inputs": "((T([32, 16, 196, 3, 4, 32], f32), [32, 16, 196, 384]), {})"
    },
    "aten.add.Tensor": {
        "count": 80,
        "inputs": "((T([32, 1, 196, 512], f32), T([32, 1, 196, 512], f32)), {})"
    },
    "aten.addmm.default": {
        "count": 1,
        "inputs": "((T([1000], f32), T([32, 512], f32), T([512, 1000], f32, stride=(1, 512))), {})"
    },
    "aten.as_strided_.default": {
        "count": 1,
        "inputs": "((T([32, 512, 1, 1], f32), [32, 512, 1, 1], [512, 1, 512, 512]), {})"
    },
    "aten.bernoulli_.float": {
        "count": 2,
        "inputs": "((T([32, 1, 1, 1], f32),), {})"
    },
    "aten.bmm.default": {
        "count": 2,
        "inputs": "((T([2048, 196, 196], f32), T([2048, 196, 32], f32, stride=(6272, 1, 196))), {})"
    },
    "aten.clone.default": {
        "count": 1,
        "inputs": "((T([1000, 512], f32),), {})"
    },
    "aten.constant_pad_nd.default": {
        "count": 1,
        "inputs": "((T([32, 256, 57, 57], f32, stride=(831744, 1, 14592, 256)), [0, -1, 0, -1]), {})"
    },
    "aten.convolution.default": {
        "count": 1,
        "inputs": "((T([32, 256, 28, 28], f32, stride=(200704, 1, 7168, 256)), T([512, 256, 3, 3], f32), T([512], f32), [1, 1], [1, 1], [1, 1], False, [0, 0], 1), {})"
    },
    "aten.convolution_backward.default": {
        "count": 1,
        "inputs": "((T([32, 128, 56, 56], f32, stride=(401408, 1, 7168, 128)), T([32, 3, 224, 224], f32), T([128, 3, 4, 4], f32), [128], [4, 4], [0, 0], [1, 1], False, [0, 0], 1, [False, True, True]), {})"
    },
    "aten.copy_.default": {
        "count": 1,
        "inputs": "((T([256, 128, 3, 3], f32), T([256, 128, 3, 3], f32, stride=(1152, 1, 384, 128))), {})"
    },
    "aten.div.Scalar": {
        "count": 1,
        "inputs": "((T([32, 512, 14, 14], f32, stride=(512, 1, 0, 0)), 196), {})"
    },
    "aten.div_.Tensor": {
        "count": 2,
        "inputs": "((T([32, 1, 1, 1], f32), 0.5), {})"
    },
    "aten.gelu.default": {
        "count": 20,
        "inputs": "((T([32, 1, 196, 2048], f32),), {})"
    },
    "aten.gelu_backward.default": {
        "count": 2,
        "inputs": "((T([32, 16, 196, 512], f32), T([32, 16, 196, 512], f32)), {})"
    },
    "aten.max_pool2d_with_indices.default": {
        "count": 1,
        "inputs": "((T([32, 512, 29, 29], f32, stride=(430592, 1, 14848, 512)), [3, 3], [2, 2]), {})"
    },
    "aten.max_pool2d_with_indices_backward.default": {
        "count": 1,
        "inputs": "((T([32, 256, 28, 28], f32, stride=(200704, 1, 7168, 256)), T([32, 256, 57, 57], f32, stride=(831744, 1, 14592, 256)), [3, 3], [2, 2], [0, 0], [1, 1], False, T([32, 256, 28, 28], i64, stride=(200704, 1, 7168, 256))), {})"
    },
    "aten.mean.dim": {
        "count": 1,
        "inputs": "((T([32, 512, 14, 14], f32, stride=(100352, 1, 7168, 512)), [-1, -2], True), {})"
    },
    "aten.mm.default": {
        "count": 2,
        "inputs": "((T([384, 100352], f32, stride=(1, 384)), T([100352, 128], f32)), {})"
    },
    "aten.mul.Scalar": {
        "count": 2,
        "inputs": "((T([32, 4, 16, 196, 32], f32), 0.42044820762685725), {})"
    },
    "aten.mul.Tensor": {
        "count": 80,
        "inputs": "((T([32, 1, 196, 512], f32), T([32, 1, 1, 1], f32)), {})"
    },
    "aten.native_layer_norm.default": {
        "count": 1,
        "inputs": "((T([32, 14, 14, 512], f32), [512], T([512], f32), T([512], f32), 1e-06), {})"
    },
    "aten.native_layer_norm_backward.default": {
        "count": 4,
        "inputs": "((T([32, 16, 196, 128], f32), T([32, 16, 196, 128], f32), [128], T([32, 16, 196, 1], f32), T([32, 16, 196, 1], f32), T([128], f32), T([128], f32), [True, True, True]), {})"
    },
    "aten.new_empty.default": {
        "count": 40,
        "inputs": "((T([32, 1, 196, 512], f32), [32, 1, 1, 1]), {'pin_memory': False})"
    },
    "aten.new_empty_strided.default": {
        "count": 1,
        "inputs": "((T([256, 128, 3, 3], f32, stride=(1152, 1, 384, 128)), [256, 128, 3, 3], [1152, 9, 3, 1]), {'dtype': f32, 'layout': torch.strided, 'device': 'cuda'})"
    },
    "aten.new_zeros.default": {
        "count": 1,
        "inputs": "((T([32, 512], f32), [16384]), {})"
    },
    "aten.nll_loss_backward.default": {
        "count": 1,
        "inputs": "((T([], f32), T([32, 1000], f32), T([32], i64), None, 1, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 1,
        "inputs": "((T([32, 1000], f32), T([32], i64), None, 1, -100), {})"
    },
    "aten.random_.to": {
        "count": 1,
        "inputs": "((T([32], i64), 1000), {})"
    },
    "aten.stack.default": {
        "count": 2,
        "inputs": "(([T([32, 4, 16, 196, 32], f32), T([32, 4, 16, 196, 32], f32, stride=(401408, 100352, 6272, 1, 196)), T([32, 4, 16, 196, 32], f32)],), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 1,
        "inputs": "((T([32, 16, 196, 128], f32), [0], True), {})"
    },
    "aten.unbind.int": {
        "count": 20,
        "inputs": "((T([3, 32, 16, 1, 196, 32], f32, stride=(512, 301056, 32, 301056, 1536, 1)),), {})"
    }
}