{
    "aten._foreach_add.List": {
        "count": 1,
        "inputs": "(([T([768, 3, 16, 16], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([2304, 768], f32), T([768, 768], f32), T([3072, 768], f32), T([768, 3072], f32), T([2304, 768], f32), T([768, 768], f32), T([3072, 768], f32), T([768, 3072], f32), T([1000, 768], f32)], [T([768, 3, 16, 16], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([1536, 768], f32), T([768, 768], f32), T([768, 768], f32), T([16, 3], f32), T([3072, 768], f32), T([768, 3072], f32), T([2304, 768], f32), T([768, 768], f32), T([3072, 768], f32), T([768, 3072], f32), T([2304, 768], f32), T([768, 768], f32), T([3072, 768], f32), T([768, 3072], f32), T([1000, 768], f32)]), {'alpha': 0.0001})"
    },
    "aten._log_softmax.default": {
        "count": 1,
        "inputs": "((T([64, 1000], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 1,
        "inputs": "((T([64, 1000], f32), T([64, 1000], f32), 1, f32), {})"
    },
    "aten._softmax.default": {
        "count": 2,
        "inputs": "((T([64, 16, 197, 197], f32), -1, False), {})"
    },
    "aten._softmax_backward_data.default": {
        "count": 20,
        "inputs": "((T([64, 16, 196, 196], f32), T([64, 16, 196, 196], f32), -1, f32), {})"
    },
    "aten._to_copy.default": {
        "count": 10,
        "inputs": "((T([1, 196, 196, 3], f32),), {'dtype': f32, 'layout': torch.strided, 'device': 'cuda'})"
    },
    "aten._unsafe_view.default": {
        "count": 10,
        "inputs": "((T([64, 196, 2, 16, 48], f32), [64, 196, 1536]), {})"
    },
    "aten.add.Tensor": {
        "count": 29,
        "inputs": "((T([64, 196, 768], f32), T([64, 196, 768], f32)), {})"
    },
    "aten.addmm.default": {
        "count": 1,
        "inputs": "((T([1000], f32), T([64, 768], f32, stride=(151296, 1)), T([768, 1000], f32, stride=(1, 768))), {})"
    },
    "aten.bmm.default": {
        "count": 10,
        "inputs": "((T([1024, 196, 196], f32), T([1024, 196, 48], f32, stride=(9408, 1, 196))), {})"
    },
    "aten.cat.default": {
        "count": 1,
        "inputs": "(([T([64, 1, 768], f32, stride=(0, 768, 1)), T([64, 196, 768], f32, stride=(150528, 1, 196))], 1), {})"
    },
    "aten.clone.default": {
        "count": 1,
        "inputs": "((T([1000, 768], f32),), {})"
    },
    "aten.convolution.default": {
        "count": 1,
        "inputs": "((T([64, 3, 224, 224], f32), T([768, 3, 16, 16], f32), T([768], f32), [16, 16], [0, 0], [1, 1], False, [0, 0], 1), {})"
    },
    "aten.convolution_backward.default": {
        "count": 1,
        "inputs": "((T([64, 768, 14, 14], f32, stride=(150528, 1, 10752, 768)), T([64, 3, 224, 224], f32), T([768, 3, 16, 16], f32), [768], [16, 16], [0, 0], [1, 1], False, [0, 0], 1, [False, True, True]), {})"
    },
    "aten.copy_.default": {
        "count": 30,
        "inputs": "((T([1, 196, 196], f32, stride=(115248, 588, 3)), T([1, 196, 196], i64)), {})"
    },
    "aten.div.Tensor": {
        "count": 30,
        "inputs": "((T([64, 16, 196, 196], f32), T([64, 16, 196, 1], f32)), {})"
    },
    "aten.div_.Tensor": {
        "count": 10,
        "inputs": "((T([64, 16, 196, 196], f32), T([64, 16, 196, 1], f32)), {})"
    },
    "aten.gelu.default": {
        "count": 2,
        "inputs": "((T([64, 197, 3072], f32),), {})"
    },
    "aten.gelu_backward.default": {
        "count": 10,
        "inputs": "((T([64, 196, 3072], f32), T([64, 196, 3072], f32)), {})"
    },
    "aten.mm.default": {
        "count": 10,
        "inputs": "((T([12544, 1536], f32), T([1536, 768], f32)), {})"
    },
    "aten.mul.Tensor": {
        "count": 20,
        "inputs": "((T([64, 16, 196, 196], f32), T([1, 16, 1, 1], f32)), {})"
    },
    "aten.native_layer_norm.default": {
        "count": 5,
        "inputs": "((T([64, 197, 768], f32), [768], T([768], f32), T([768], f32), 1e-06), {})"
    },
    "aten.native_layer_norm_backward.default": {
        "count": 20,
        "inputs": "((T([64, 196, 768], f32), T([64, 196, 768], f32, stride=(150528, 1, 196)), [768], T([64, 196, 1], f32), T([64, 196, 1], f32), T([768], f32), T([768], f32), [True, True, True]), {})"
    },
    "aten.neg.default": {
        "count": 10,
        "inputs": "((T([1, 16, 1, 1], f32),), {})"
    },
    "aten.nll_loss_backward.default": {
        "count": 1,
        "inputs": "((T([], f32), T([64, 1000], f32), T([64], i64), None, 1, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 1,
        "inputs": "((T([64, 1000], f32), T([64], i64), None, 1, -100), {})"
    },
    "aten.pow.Tensor_Scalar": {
        "count": 20,
        "inputs": "((T([196, 196], i64), 2), {})"
    },
    "aten.random_.to": {
        "count": 1,
        "inputs": "((T([64], i64), 1000), {})"
    },
    "aten.repeat.default": {
        "count": 10,
        "inputs": "((T([14, 14], i64), [14, 14]), {})"
    },
    "aten.rsub.Scalar": {
        "count": 10,
        "inputs": "((T([1, 16, 1, 1], f32), 1.0), {})"
    },
    "aten.select_backward.default": {
        "count": 10,
        "inputs": "((T([64, 16, 196, 48], f32), [2, 64, 16, 196, 48], 0, 0), {})"
    },
    "aten.sigmoid.default": {
        "count": 20,
        "inputs": "((T([1, 16, 1, 1], f32),), {})"
    },
    "aten.sigmoid_backward.default": {
        "count": 20,
        "inputs": "((T([1, 16, 1, 1], f32), T([1, 16, 1, 1], f32)), {})"
    },
    "aten.stack.default": {
        "count": 2,
        "inputs": "(([T([64, 16, 197, 48], f32), T([64, 16, 197, 48], f32, stride=(151296, 9456, 1, 197)), T([64, 16, 197, 48], f32)],), {})"
    },
    "aten.sub.Tensor": {
        "count": 10,
        "inputs": "((T([1, 14], i64), T([14, 1], i64)), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 1,
        "inputs": "((T([64, 196, 768], f32), [0], True), {})"
    },
    "aten.unbind.int": {
        "count": 2,
        "inputs": "((T([3, 64, 16, 197, 48], f32, stride=(768, 453888, 48, 2304, 1)),), {})"
    }
}