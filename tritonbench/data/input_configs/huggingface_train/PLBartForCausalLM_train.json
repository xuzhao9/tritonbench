{
    "aten._log_softmax.default": {
        "count": 1,
        "inputs": "((T([8192, 50005], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 1,
        "inputs": "((T([8192, 50005], f32), T([8192, 50005], f32), 1, f32), {})"
    },
    "aten._scaled_dot_product_efficient_attention.default": {
        "count": 6,
        "inputs": "((T([8, 12, 1024, 64], f32), T([8, 12, 1024, 64], f32), T([8, 12, 1024, 64], f32), None, True, 0.1, True), {'scale': 0.125})"
    },
    "aten._scaled_dot_product_efficient_attention_backward.default": {
        "count": 6,
        "inputs": "((T([8, 12, 1024, 64], f32, stride=(786432, 64, 768, 1)), T([8, 12, 1024, 64], f32), T([8, 12, 1024, 64], f32), T([8, 12, 1024, 64], f32), None, T([8, 12, 1024, 64], f32, stride=(786432, 64, 768, 1)), T([8, 12, 1024], f32), T([], i64), T([], i64), 0.1, [True, True, True, False], True), {'scale': 0.125})"
    },
    "aten._unsafe_view.default": {
        "count": 1,
        "inputs": "((T([8192, 50005], f32), [8, 1024, 50005]), {})"
    },
    "aten.add.Tensor": {
        "count": 1,
        "inputs": "((T([50005, 768], f32), T([50005, 768], f32)), {})"
    },
    "aten.addmm.default": {
        "count": 6,
        "inputs": "((T([768], f32), T([8192, 3072], f32), T([3072, 768], f32, stride=(1, 3072))), {})"
    },
    "aten.all.default": {
        "count": 1,
        "inputs": "((T([8, 1024], b8),), {})"
    },
    "aten.embedding.default": {
        "count": 1,
        "inputs": "((T([1026, 768], f32), T([1, 1024], i64)), {})"
    },
    "aten.embedding_dense_backward.default": {
        "count": 1,
        "inputs": "((T([8, 1024, 768], f32), T([8, 1024], i64), 50005, 1, False), {})"
    },
    "aten.eq.Scalar": {
        "count": 1,
        "inputs": "((T([8, 1024], f32), 1), {})"
    },
    "aten.gelu.default": {
        "count": 6,
        "inputs": "((T([8, 1024, 3072], f32),), {})"
    },
    "aten.gelu_backward.default": {
        "count": 6,
        "inputs": "((T([8, 1024, 3072], f32), T([8, 1024, 3072], f32)), {})"
    },
    "aten.lt.Scalar": {
        "count": 6,
        "inputs": "((T([], f32), 0.0), {})"
    },
    "aten.mm.default": {
        "count": 24,
        "inputs": "((T([768, 8192], f32, stride=(1, 768)), T([8192, 768], f32)), {})"
    },
    "aten.mul.Tensor": {
        "count": 2,
        "inputs": "((T([8, 1024, 768], f32), 27.712812921102035), {})"
    },
    "aten.native_dropout.default": {
        "count": 13,
        "inputs": "((T([8, 1024, 768], f32), 0.1, True), {})"
    },
    "aten.native_dropout_backward.default": {
        "count": 13,
        "inputs": "((T([8, 1024, 768], f32), T([8, 1024, 768], b8), 1.1111111111111112), {})"
    },
    "aten.native_layer_norm.default": {
        "count": 13,
        "inputs": "((T([8, 1024, 768], f32), [768], T([768], f32), T([768], f32), 1e-05), {})"
    },
    "aten.native_layer_norm_backward.default": {
        "count": 13,
        "inputs": "((T([8, 1024, 768], f32), T([8, 1024, 768], f32), [768], T([8, 1024, 1], f32), T([8, 1024, 1], f32), T([768], f32), T([768], f32), [True, True, True]), {})"
    },
    "aten.nll_loss_backward.default": {
        "count": 1,
        "inputs": "((T([], f32), T([8192, 50005], f32), T([8192], i64), None, 1, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 1,
        "inputs": "((T([8192, 50005], f32), T([8192], i64), None, 1, -100), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 1,
        "inputs": "((T([8, 1024, 768], f32), [0], True), {})"
    }
}