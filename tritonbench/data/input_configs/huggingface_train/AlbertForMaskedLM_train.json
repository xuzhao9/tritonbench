{
    "aten._log_softmax.default": {
        "count": 1,
        "inputs": "((T([2048, 30000], f32), 1, False), {})"
    },
    "aten._log_softmax_backward_data.default": {
        "count": 1,
        "inputs": "((T([2048, 30000], f32), T([2048, 30000], f32), 1, f32), {})"
    },
    "aten._scaled_dot_product_efficient_attention.default": {
        "count": 12,
        "inputs": "((T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), None, True), {})"
    },
    "aten._scaled_dot_product_efficient_attention_backward.default": {
        "count": 12,
        "inputs": "((T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), None, T([4, 64, 512, 64], f32, stride=(2097152, 64, 4096, 1)), T([4, 64, 512], f32), T([], i64), T([], i64), 0.0, [True, True, True, False]), {})"
    },
    "aten.add.Tensor": {
        "count": 1,
        "inputs": "((T([30000, 128], f32), T([30000, 128], f32)), {})"
    },
    "aten.add_.Tensor": {
        "count": 1,
        "inputs": "((T([4, 512, 128], f32), T([1, 512, 128], f32)), {})"
    },
    "aten.addmm.default": {
        "count": 1,
        "inputs": "((T([30000], f32), T([2048, 128], f32), T([128, 30000], f32, stride=(1, 128))), {})"
    },
    "aten.all.default": {
        "count": 1,
        "inputs": "((T([4, 512], b8),), {})"
    },
    "aten.any.default": {
        "count": 1,
        "inputs": "((T([4, 2], b8),), {})"
    },
    "aten.embedding.default": {
        "count": 1,
        "inputs": "((T([512, 128], f32), T([1, 512], i64)), {})"
    },
    "aten.embedding_dense_backward.default": {
        "count": 1,
        "inputs": "((T([4, 512, 128], f32), T([4, 512], i64), 30000, 0, False), {})"
    },
    "aten.eq.Scalar": {
        "count": 1,
        "inputs": "((T([4, 512], f32), 1), {})"
    },
    "aten.index.Tensor": {
        "count": 1,
        "inputs": "((T([4, 512], i64), [None, T([2], i64)]), {})"
    },
    "aten.mm.default": {
        "count": 1,
        "inputs": "((T([4096, 2048], f32, stride=(1, 4096)), T([2048, 128], f32)), {})"
    },
    "aten.mul.Scalar": {
        "count": 12,
        "inputs": "((T([4, 512, 16384], f32), 3.0), {})"
    },
    "aten.mul.Tensor": {
        "count": 4,
        "inputs": "((T([4, 512, 128], f32), T([4, 512, 128], f32)), {})"
    },
    "aten.native_layer_norm.default": {
        "count": 24,
        "inputs": "((T([4, 512, 4096], f32), [4096], T([4096], f32), T([4096], f32), 1e-12), {})"
    },
    "aten.native_layer_norm_backward.default": {
        "count": 24,
        "inputs": "((T([4, 512, 4096], f32), T([4, 512, 4096], f32), [4096], T([4, 512, 1], f32), T([4, 512, 1], f32), T([4096], f32), T([4096], f32), [True, True, True]), {})"
    },
    "aten.nll_loss_backward.default": {
        "count": 1,
        "inputs": "((T([], f32), T([2048, 30000], f32), T([2048], i64), None, 1, -100, T([], f32)), {})"
    },
    "aten.nll_loss_forward.default": {
        "count": 1,
        "inputs": "((T([2048, 30000], f32), T([2048], i64), None, 1, -100), {})"
    },
    "aten.pow.Tensor_Scalar": {
        "count": 12,
        "inputs": "((T([4, 512, 16384], f32), 2.0), {})"
    },
    "aten.sum.dim_IntList": {
        "count": 1,
        "inputs": "((T([4, 512, 128], f32), [0], True), {})"
    },
    "aten.tanh.default": {
        "count": 1,
        "inputs": "((T([4, 512, 128], f32),), {})"
    },
    "aten.tanh_backward.default": {
        "count": 12,
        "inputs": "((T([4, 512, 16384], f32), T([4, 512, 16384], f32)), {})"
    }
}